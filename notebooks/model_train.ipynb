{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем готовый csv с описанием компонента и энкодированным ТНВЭД кодом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\\\data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение объектов по 85 классам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TNVED_encoded\n",
      "72    2247\n",
      "46     910\n",
      "37     789\n",
      "35     645\n",
      "51     571\n",
      "      ... \n",
      "55       8\n",
      "59       6\n",
      "3        5\n",
      "0        3\n",
      "2        1\n",
      "Name: count, Length: 84, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['TNVED_encoded'].hist(bins=85)\n",
    "plt.show()\n",
    "print(data['TNVED_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем выборки и токенизируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text'].to_list()\n",
    "y = data['TNVED_encoded'].to_list()\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "   X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем датасеты и даталоудеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, y_train)\n",
    "val_dataset = CustomDataset(val_encodings, y_val)\n",
    "test_dataset = CustomDataset(test_encodings, y_test)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=84, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=84)\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def validate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits,labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    return classification_report(y_true=y_true, y_pred=y_pred, labels=range(85))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:16<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 3.8604982393677885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.0427749977316907\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:18<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 2.4592593026600675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.8964021269993117\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:20<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 1.542585368804668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.2491773799542458\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:20<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9913998044306233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9259789983431498\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:20<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.6667011192386052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7327475113573895\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:21<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.44883954528427344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6403483270957906\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:21<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.3064695886563733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5516464147035793\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:21<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.20683348051825975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5477591208632915\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:21<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.1552946421957236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.46969778711597127\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:21<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.11278923555418918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5318537664509588\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:20<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.09333743715512863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5112977033400888\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:20<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.06840593625752744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4734157392935407\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 434/434 [03:20<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.04613961536257017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.49557076677960415\n",
      "!===Early stopping===!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "trigger_count = 0\n",
    "for epoch in range(20):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    avg_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    print(f\"Average Loss: {avg_loss}\")\n",
    "\n",
    "    val_loss = validate_model(model, val_loader, device)\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        trigger_count = 0\n",
    "        model.save_pretrained(\"best_model_distilbert\")\n",
    "        \n",
    "    else: \n",
    "        trigger_count+=1\n",
    "        if trigger_count>patience: \n",
    "            print('!===Early stopping===!')\n",
    "            break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 93/93 [00:15<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.67      0.80      0.73         5\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      1.00      0.67         2\n",
      "           5       1.00      0.75      0.86         4\n",
      "           6       1.00      0.86      0.92         7\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.60      1.00      0.75         3\n",
      "           9       0.75      0.86      0.80         7\n",
      "          10       0.50      1.00      0.67         1\n",
      "          11       0.80      0.86      0.83        14\n",
      "          12       0.50      1.00      0.67         1\n",
      "          13       0.96      0.92      0.94        26\n",
      "          14       1.00      0.98      0.99        47\n",
      "          15       0.67      1.00      0.80         2\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      0.88      0.93         8\n",
      "          20       0.67      0.67      0.67         3\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         8\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       1.00      0.67      0.80         3\n",
      "          25       0.80      0.80      0.80         5\n",
      "          26       0.67      1.00      0.80         2\n",
      "          27       1.00      1.00      1.00         9\n",
      "          28       0.94      1.00      0.97        17\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.75      1.00      0.86         3\n",
      "          32       1.00      1.00      1.00        17\n",
      "          33       0.97      0.97      0.97        35\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       1.00      1.00      1.00        82\n",
      "          36       0.75      0.90      0.82        10\n",
      "          37       1.00      0.99      1.00       123\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       1.00      0.88      0.93        16\n",
      "          40       1.00      1.00      1.00         4\n",
      "          41       0.83      1.00      0.91         5\n",
      "          42       1.00      1.00      1.00         5\n",
      "          43       0.50      0.67      0.57         3\n",
      "          44       1.00      0.60      0.75         5\n",
      "          45       0.82      0.82      0.82        11\n",
      "          46       0.91      0.83      0.87       145\n",
      "          47       0.58      0.71      0.64        35\n",
      "          48       1.00      0.57      0.73         7\n",
      "          49       0.74      0.76      0.75        38\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.97      0.88      0.92        96\n",
      "          52       0.69      0.58      0.63        19\n",
      "          53       0.82      0.96      0.89        49\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       1.00      1.00      1.00        12\n",
      "          57       1.00      1.00      1.00         4\n",
      "          58       0.82      1.00      0.90        14\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       1.00      0.86      0.92        21\n",
      "          62       1.00      1.00      1.00        22\n",
      "          63       1.00      0.75      0.86         4\n",
      "          64       0.33      1.00      0.50         1\n",
      "          65       0.75      1.00      0.86         3\n",
      "          66       0.78      1.00      0.88         7\n",
      "          67       1.00      0.80      0.89         5\n",
      "          68       1.00      0.86      0.92         7\n",
      "          69       1.00      1.00      1.00         5\n",
      "          70       0.95      0.98      0.97        64\n",
      "          71       0.92      0.92      0.92        36\n",
      "          72       0.98      0.96      0.97       331\n",
      "          73       0.62      1.00      0.76         8\n",
      "          74       1.00      0.75      0.86         4\n",
      "          75       0.50      1.00      0.67         2\n",
      "          76       1.00      1.00      1.00         7\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.50      1.00      0.67         2\n",
      "          79       1.00      0.80      0.89         5\n",
      "          80       1.00      1.00      1.00         3\n",
      "          81       0.89      1.00      0.94         8\n",
      "          82       1.00      0.88      0.93         8\n",
      "          83       1.00      1.00      1.00         5\n",
      "          84       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91      1488\n",
      "   macro avg       0.70      0.73      0.70      1488\n",
      "weighted avg       0.93      0.91      0.92      1488\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Shamaich\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "report_distill_bert = evaluate_model(model, test_loader, device)\n",
    "print(report_distill_bert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                 precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         0\n",
    "           1       0.67      0.80      0.73         5\n",
    "           2       0.00      0.00      0.00         0\n",
    "           3       0.00      0.00      0.00         1\n",
    "           4       0.50      1.00      0.67         2\n",
    "           5       1.00      0.75      0.86         4\n",
    "           6       1.00      0.86      0.92         7\n",
    "           7       1.00      0.67      0.80         3\n",
    "           8       0.60      1.00      0.75         3\n",
    "           9       0.75      0.86      0.80         7\n",
    "          10       0.50      1.00      0.67         1\n",
    "          11       0.80      0.86      0.83        14\n",
    "          12       0.50      1.00      0.67         1\n",
    "          13       0.96      0.92      0.94        26\n",
    "          14       1.00      0.98      0.99        47\n",
    "          15       0.67      1.00      0.80         2\n",
    "          16       0.00      0.00      0.00         1\n",
    "          17       0.00      0.00      0.00         0\n",
    "          18       1.00      1.00      1.00         2\n",
    "          19       1.00      0.88      0.93         8\n",
    "          20       0.67      0.67      0.67         3\n",
    "          21       1.00      1.00      1.00         3\n",
    "          22       1.00      1.00      1.00         8\n",
    "          23       0.00      0.00      0.00         1\n",
    "          24       1.00      0.67      0.80         3\n",
    "          25       0.80      0.80      0.80         5\n",
    "          26       0.67      1.00      0.80         2\n",
    "          27       1.00      1.00      1.00         9\n",
    "          28       0.94      1.00      0.97        17\n",
    "          29       0.00      0.00      0.00         1\n",
    "          30       0.00      0.00      0.00         0\n",
    "          31       0.75      1.00      0.86         3\n",
    "          32       1.00      1.00      1.00        17\n",
    "          33       0.97      0.97      0.97        35\n",
    "          34       0.00      0.00      0.00         2\n",
    "          35       1.00      1.00      1.00        82\n",
    "          36       0.75      0.90      0.82        10\n",
    "          37       1.00      0.99      1.00       123\n",
    "          38       0.00      0.00      0.00         0\n",
    "          39       1.00      0.88      0.93        16\n",
    "          40       1.00      1.00      1.00         4\n",
    "          41       0.83      1.00      0.91         5\n",
    "          42       1.00      1.00      1.00         5\n",
    "          43       0.50      0.67      0.57         3\n",
    "          44       1.00      0.60      0.75         5\n",
    "          45       0.82      0.82      0.82        11\n",
    "          46       0.91      0.83      0.87       145\n",
    "          47       0.58      0.71      0.64        35\n",
    "          48       1.00      0.57      0.73         7\n",
    "          49       0.74      0.76      0.75        38\n",
    "          50       0.00      0.00      0.00         1\n",
    "          51       0.97      0.88      0.92        96\n",
    "          52       0.69      0.58      0.63        19\n",
    "          53       0.82      0.96      0.89        49\n",
    "          54       1.00      1.00      1.00         2\n",
    "          55       0.00      0.00      0.00         0\n",
    "          56       1.00      1.00      1.00        12\n",
    "          57       1.00      1.00      1.00         4\n",
    "          58       0.82      1.00      0.90        14\n",
    "          59       0.00      0.00      0.00         1\n",
    "          60       0.00      0.00      0.00         0\n",
    "          61       1.00      0.86      0.92        21\n",
    "          62       1.00      1.00      1.00        22\n",
    "          63       1.00      0.75      0.86         4\n",
    "          64       0.33      1.00      0.50         1\n",
    "          65       0.75      1.00      0.86         3\n",
    "          66       0.78      1.00      0.88         7\n",
    "          67       1.00      0.80      0.89         5\n",
    "          68       1.00      0.86      0.92         7\n",
    "          69       1.00      1.00      1.00         5\n",
    "          70       0.95      0.98      0.97        64\n",
    "          71       0.92      0.92      0.92        36\n",
    "          72       0.98      0.96      0.97       331\n",
    "          73       0.62      1.00      0.76         8\n",
    "          74       1.00      0.75      0.86         4\n",
    "          75       0.50      1.00      0.67         2\n",
    "          76       1.00      1.00      1.00         7\n",
    "          77       0.00      0.00      0.00         0\n",
    "          78       0.50      1.00      0.67         2\n",
    "          79       1.00      0.80      0.89         5\n",
    "          80       1.00      1.00      1.00         3\n",
    "          81       0.89      1.00      0.94         8\n",
    "          82       1.00      0.88      0.93         8\n",
    "          83       1.00      1.00      1.00         5\n",
    "          84       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.91      1488\n",
    "    macro avg      0.70      0.73      0.70      1488\n",
    "    weighted avg   0.93      0.91      0.92      1488\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
