# TNVED Code Classifier from Electronic Component Datasheets

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø–æ –∫–æ–¥–∞–º –¢–ù–í–≠–î –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö datasheet'–æ–≤ –∏ –º–æ–¥–µ–ª–∏ DistilBERT.

## –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–°–æ–∫—Ä–∞—Ç–∏—Ç—å —Ä—É—Ç–∏–Ω–Ω—É—é –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ª–æ–≥–∏—Å—Ç–∏–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¢–ù–í–≠–î-–∫–æ–¥–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º—ã—Ö —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤. –ú–æ–¥–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî `part number`, `manufacturer`, –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ datasheet ‚Äî –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –¢–ù–í–≠–î-–∫–æ–¥.

## –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ø–æ–¥—Ö–æ–¥

–ú–æ–¥–µ–ª—å DistilBERT –¥–æ–æ–±—É—á–µ–Ω–∞ –Ω–∞ –∫–æ—Ä–ø—É—Å–µ —Å –∫—Ä–∞—Ç–∫–∏–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (summary datasheets) –∏ –º–µ—Ç–∫–∞–º–∏ –¢–ù–í–≠–î. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ Jupyter Notebook. –ü—Ä–æ–µ–∫—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–∞–∫ –æ—Å–Ω–æ–≤–∞ –¥–ª—è API-—Å–µ—Ä–≤–∏—Å–∞.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
.
‚îú‚îÄ‚îÄ best_model_distilbert/      # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (HuggingFace format)
‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îî‚îÄ‚îÄ model.safetensors
‚îú‚îÄ‚îÄ data/                       # –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ inference
‚îÇ   ‚îú‚îÄ‚îÄ datasheets/             # –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ datasheets (txt)
‚îÇ   ‚îú‚îÄ‚îÄ data.csv                # –û—á–∏—â–µ–Ω–Ω—ã–π csv
‚îÇ   ‚îî‚îÄ‚îÄ df_clear_uniq_3.csv		# –ò—Å—Ö–æ–¥–Ω—ã–π csv
‚îÇ   ‚îî‚îÄ‚îÄ label_encoder.joblib	# –≠–Ω–∫–æ–¥–µ—Ä –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ 
‚îú‚îÄ‚îÄ notebooks/                  # Jupyter –Ω–æ—É—Ç–±—É–∫–∏ —Å –ø–∞–π–ø–ª–∞–π–Ω–æ–º
‚îÇ   ‚îú‚îÄ‚îÄ data_extraction.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ model_train.ipynb
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
```

## –°—Ç–µ–∫

- `transformers`, `datasets`, `tokenizers` ‚Äî —Ä–∞–±–æ—Ç–∞ —Å DistilBERT

- `pandas`, `numpy`, `scikit-learn` ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç—Ä–∏–∫

- `PyTorch` ‚Äî –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

  

## –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:

```bash
pip install -r requirements.txt
```

2. –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ—É—Ç–±—É–∫ –∏–∑ –ø–∞–ø–∫–∏ `notebooks/`, —á—Ç–æ–±—ã:

- –ø—Ä–æ–≤–µ—Å—Ç–∏ inference
- –¥–æ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏

3. –ú–æ–¥–µ–ª—å `best_model_distilbert/` –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ `transformers`:

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("best_model_distilbert")
tokenizer = AutoTokenizer.from_pretrained("best_model_distilbert")
```

## üõ†Ô∏è –ó–∞–ø—É—Å–∫ inference

–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞:

```python
def predict_tnved(text, model, tokenizer):
    inputs = tokenizer(text, return_tensors="pt", truncation=True)
    outputs = model(**inputs)
    predicted_class = outputs.logits.argmax(dim=-1).item()
    return predicted_class
```

